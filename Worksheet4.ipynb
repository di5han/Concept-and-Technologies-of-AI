{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jCfrywn_xV48F-cC3sMW6Va8fPDLnCqj",
      "authorship_tag": "ABX9TyNpqAK1A0QJokSnUynUkIdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/di5han/Concept-and-Technologies-of-AI/blob/main/Worksheet4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTCDvr-qgl65",
        "outputId": "b39ed2d1-a17d-428e-c07a-6f54fa3d1417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data after processing:\n",
            "    PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
            "0            1         0       3  22.0      1      0   7.2500\n",
            "1            2         1       1  38.0      1      0  71.2833\n",
            "2            3         1       3  26.0      0      0   7.9250\n",
            "3            4         1       1  35.0      1      0  53.1000\n",
            "4            5         0       3  35.0      0      0   8.0500\n",
            "\n",
            "Missing values after processing:\n",
            " PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Fare           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Load the Titanic dataset\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset/Titanic-Dataset.csv\")\n",
        "# Drop all categorical columns except 'Survived'\n",
        "categorical_columns = data.select_dtypes(include=['object']).columns\n",
        "data = data.drop(columns=[col for col in categorical_columns if col != 'Survived'])\n",
        "# Check for missing values\n",
        "missing_info = data.isnull().sum() / len(data) * 100\n",
        "# Handle missing values\n",
        "for column in data.columns:\n",
        "    if missing_info[column] > 10: # If more than 10% missing\n",
        "        data[column] = data[column].fillna(data[column].mean())\n",
        "    else: # If less than 10% missing\n",
        "        # For dropna, direct assignment handles it better than inplace=True\n",
        "        # This line drops rows where the specific column has NaN if the percentage is low\n",
        "        # Reassigning the result ensures changes are reflected in the DataFrame\n",
        "        data = data.dropna(subset=[column])\n",
        "# Display cleaned data\n",
        "print(\"Data after processing:\\n\", data.head())\n",
        "print(\"\\nMissing values after processing:\\n\", data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Separate features (X) and target (y)\n",
        "X = data.drop(columns=['Survived']).values # Convert features to NumPy array\n",
        "y = data['Survived'].values # Convert target to NumPy array\n",
        "# Define a function for train-test split from scratch\n",
        "def train_test_split_scratch(X, y, test_size=0.3, random_seed=42):\n",
        "    \"\"\"\n",
        "    Splits dataset into train and test sets.\n",
        "\n",
        "    Arguments:\n",
        "    X : np.ndarray\n",
        "        Feature matrix.\n",
        "    y : np.ndarray\n",
        "        Target array.\n",
        "    test_size : float\n",
        "        Proportion of the dataset to include in the test split (0 < test_size < 1).\n",
        "    random_seed : int\n",
        "        Seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test : np.ndarray\n",
        "        Training and testing splits of features and target.\n",
        "    \"\"\"\n",
        "    np.random.seed(random_seed)\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices) # Shuffle the indices\n",
        "    test_split_size = int(len(X) * test_size)\n",
        "    test_indices = indices[:test_split_size]\n",
        "    train_indices = indices[test_split_size:]\n",
        "\n",
        "    X_train, X_test = X[train_indices], X[test_indices]\n",
        "    y_train, y_test = y[train_indices], y[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Perform the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split_scratch(X, y, test_size=0.3)\n",
        "\n",
        "# Output shapes to verify\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmqgqUEwhRws",
        "outputId": "5d0c1d8a-ae2a-4cb8-e33d-f42bc4996b60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (624, 6)\n",
            "Shape of X_test: (267, 6)\n",
            "Shape of y_train: (624,)\n",
            "Shape of y_test: (267,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(point1, point2):\n",
        "    \"\"\"\n",
        "    Calculate the Euclidean distance between two points in n-dimensional space.\n",
        "    Arguments:\n",
        "    point1 : np.ndarray\n",
        "    The first point as a numpy array.\n",
        "    point2 : np.ndarray\n",
        "    The second point as a numpy array.\n",
        "    Returns:\n",
        "    float\n",
        "    The Euclidean distance between the two points.\n",
        "    Raises:\n",
        "    ValueError: If the input points do not have the same dimensionality.\n",
        "    \"\"\"\n",
        "    # Check if the points are of the same dimension\n",
        "    if point1.shape != point2.shape:\n",
        "        raise ValueError(\"Points must have the same dimensions to calculate Euclidean distance.\")\n",
        "    # Calculate the Euclidean distance\n",
        "    distance = np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "    return distance"
      ],
      "metadata": {
        "id": "1ZGNbAkkicQI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case for the function\n",
        "try:\n",
        "    # Define two points\n",
        "    point1 = np.array([3, 4])\n",
        "    point2 = np.array([0, 0])\n",
        "    # Calculate the distance\n",
        "    result = euclidean_distance(point1, point2)\n",
        "    # Check if the result matches the expected value (e.g., sqrt(3^2 + 4^2) = 5)\n",
        "    expected_result = 5.0\n",
        "    assert np.isclose(result, expected_result), f\"Expected {expected_result}, but got {result}\"\n",
        "    print(\"Test passed successfully!\")\n",
        "except ValueError as ve:\n",
        "    print(f\"ValueError: {ve}\")\n",
        "except AssertionError as ae:\n",
        "    print(f\"AssertionError: {ae}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn7JYTWaijIy",
        "outputId": "5071919e-38f0-4403-8ad9-7be15eda5a9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for KNN prediction for a single query\n",
        "def knn_predict_single(query, X_train, y_train, k=3):\n",
        "    \"\"\"\n",
        "    Predict the class label for a single query using the K-nearest neighbors algorithm.\n",
        "    Arguments:\n",
        "    query : np.ndarray\n",
        "    The query point for which the prediction is to be made.\n",
        "    X_train : np.ndarray\n",
        "    The training feature matrix.\n",
        "    y_train : np.ndarray\n",
        "    The training labels.\n",
        "    k : int, optional\n",
        "    The number of nearest neighbors to consider (default is 3).\n",
        "    Returns:\n",
        "    int\n",
        "    The predicted class label for the query.\n",
        "    \"\"\"\n",
        "    distances = [euclidean_distance(query, x) for x in X_train]\n",
        "    sorted_indices = np.argsort(distances)\n",
        "    nearest_indices = sorted_indices[:k]\n",
        "    nearest_labels = y_train[nearest_indices]\n",
        "    prediction = np.bincount(nearest_labels).argmax()\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "gwlmSpjQil-k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test KNN for all test samples\n",
        "def knn_predict(X_test, X_train, y_train, k=3):\n",
        "    \"\"\"\n",
        "    Predict the class labels for all test samples using the K-nearest neighbors algorithm.\n",
        "    Arguments:\n",
        "    X_test : np.ndarray\n",
        "    The test feature matrix.\n",
        "    X_train : np.ndarray\n",
        "    The training feature matrix.\n",
        "    y_train : np.ndarray\n",
        "    The training labels.\n",
        "    k : int, optional\n",
        "    The number of nearest neighbors to consider (default is 3).\n",
        "    Returns:\n",
        "    np.ndarray\n",
        "    An array of predicted class labels for the test samples.\n",
        "    \"\"\"\n",
        "    predictions = [knn_predict_single(x, X_train, y_train, k) for x in X_test]\n",
        "    return np.array(predictions)"
      ],
      "metadata": {
        "id": "nk62FjK-ioen"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case for KNN on the Titanic dataset\n",
        "# Assume X_train, X_test, y_train, and y_test have been prepared using the code above\n",
        "try:\n",
        "# Define the test set for the test case\n",
        "X_test_sample = X_test[:5] # Taking a small subset for testing\n",
        "y_test_sample = y_test[:5] # Corresponding labels for the subset\n",
        "# Make predictions\n",
        "predictions = knn_predict(X_test_sample, X_train, y_train, k=3)\n",
        "# Print test results\n",
        "print(\"Predictions:\", predictions)\n",
        "print(\"Actual labels:\", y_test_sample)\n",
        "# Check if predictions match expected format\n",
        "assert predictions.shape == y_test_sample.shape, \"The shape of predictions does not match the\n",
        "shape of the actual labels.\"\n",
        "print(\"Test case passed successfully!\")\n",
        "except AssertionError as ae:\n",
        "print(f\"AssertionError: {ae}\")\n",
        "except Exception as e:\n",
        "print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "nAMDlYAcjPzJ",
        "outputId": "620b7041-8d34-4834-d74a-17e15dd1f601"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 13) (ipython-input-1768431233.py, line 13)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1768431233.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    assert predictions.shape == y_test_sample.shape, \"The shape of predictions does not match the\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute accuracy of predictions\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "\"\"\"\n",
        "Compute the accuracy of predictions.\n",
        "Arguments:\n",
        "y_true : np.ndarray ; The true labels.\n",
        "y_pred : np.ndarray; The predicted labels.\n",
        "Returns:\n",
        "float : The accuracy as a percentage (0 to 100).\n",
        "\"\"\"\n",
        "correct_predictions = np.sum(y_true == y_pred)\n",
        "total_predictions = len(y_true)\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "return accuracy"
      ],
      "metadata": {
        "id": "srUTpB-njWRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform prediction on the entire test set\n",
        "try:\n",
        "# Make predictions on the entire test set\n",
        "predictions = knn_predict(X_test, X_train, y_train, k=3)\n",
        "# Compute the accuracy\n",
        "accuracy = compute_accuracy(y_test, predictions)\n",
        "# Print the accuracy\n",
        "print(f\"Accuracy of the KNN model on the test set: {accuracy:.2f}%\")\n",
        "except Exception as e:\n",
        "print(f\"An unexpected error occurred during prediction or accuracy computation: {e}\")"
      ],
      "metadata": {
        "id": "WWW9O54KjcnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test KNN on different values of k and plot the accuracies\n",
        "import matplotlib.pyplot as plt\n",
        "def experiment_knn_k_values(X_train, y_train, X_test, y_test, k_values):\n",
        "\"\"\"\n",
        "Run KNN predictions for different values of k and plot the accuracies.\n",
        "Arguments:\n",
        "X_train : np.ndarray\n",
        "The training feature matrix.\n",
        "y_train : np.ndarray\n",
        "The training labels.\n",
        "X_test : np.ndarray\n",
        "The test feature matrix.\n",
        "y_test : np.ndarray\n",
        "The test labels.\n",
        "k_values : list of int\n",
        "A list of k values to experiment with.\n",
        "Returns:\n",
        "dict\n",
        "A dictionary with k values as keys and their corresponding accuracies as values.\n",
        "\"\"\"\n",
        "accuracies = {}\n",
        "for k in k_values:\n",
        "# Make predictions using the current value of k\n",
        "predictions = knn_predict(X_test, X_train, y_train, k=k)\n",
        "# Compute the accuracy\n",
        "accuracy = compute_accuracy(y_test, predictions)\n",
        "accuracies[k] = accuracy\n",
        "print(f\"Accuracy for k={k}: {accuracy:.2f}%\")\n",
        "# Plot the accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(k_values, list(accuracies.values()), marker=’o’)\n",
        "plt.xlabel(’k (Number of Neighbors)’)\n",
        "plt.ylabel(’Accuracy (%)’)\n",
        "plt.title(’Accuracy of KNN with Different Values of k’)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "return accuracies"
      ],
      "metadata": {
        "id": "eofbKELIjfm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the range of k values to experiment with\n",
        "k_values = range(1, 21) # You can adjust this range as needed\n",
        "# Run the experiment\n",
        "try:\n",
        "accuracies = experiment_knn_k_values(X_train, y_train, X_test, y_test, k_values)\n",
        "print(\"Experiment completed. Check the plot for the accuracy trend.\")\n",
        "except Exception as e:\n",
        "print(f\"An unexpected error occurred during the experiment: {e}\")"
      ],
      "metadata": {
        "id": "-35GdH_tjov5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}